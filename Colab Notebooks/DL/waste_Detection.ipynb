{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "waste Detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTHKVlbC6zvsZVNpltUSW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youngpyoryu/TACO/blob/master/waste_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O194ZFxj0F68"
      },
      "source": [
        "TACO dataset(http://tacodataset.org/)\n",
        "\n",
        "ğŸŒ® is an open image dataset of waste in the wild. It contains photos of litter taken under diverse environments, from tropical beaches to London streets. These images are manually labeled and segmented according to a hierarchical taxonomy to train and evaluate object detection algorithms. The best way to know TACO is to explore our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMZMxQr80DfI"
      },
      "source": [
        "!git clone https://github.com/Youngpyoryu/TACO.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-It7G3v0TxD"
      },
      "source": [
        "!pip3 install -r /content/TACO/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaG0QHl0a0H"
      },
      "source": [
        "!python /content/TACO/download.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0QRZf5E0hp8"
      },
      "source": [
        "!git clone https://github.com/Youngpyoryu/detect-waste.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYx9QfIXViDU"
      },
      "source": [
        "!pip install funcy\n",
        "!pip install iterative-stratification==0.1.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lxPQh2A8V97"
      },
      "source": [
        "## TACO EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8LKwbjf8v_5"
      },
      "source": [
        "ìœ„ json íŒŒì¼ì—ì„œ ìš°ë¦¬ê°€ ì£¼ë¡œ ì´ìš©í•˜ê²Œ ë  ë°ì´í„°ëŠ” Imagesì™€ Annotationsì¸ë°ìš”, \n",
        "\n",
        "---\n",
        "\n",
        "ì •ë³´ê°€ í©ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— ë‘ ì •ë³´ë¥¼ ì˜ join í•´ í™œìš©í•  ìˆ˜ ìˆì–´ì•¼ í•  ë“¯í•©ë‹ˆë‹¤. ë˜í•œ ë°ì´í„° EDA, ì‹œê°í™” ë“±ì„ ìœ„í•´ì„œëŠ” í•œ Imageì— ì†í•˜ëŠ” ëª¨ë“  annotationì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ ë“±ë„ ìˆìœ¼ë©´ ì¢‹ì„ ê²ƒ ê°™ê³ ìš”. ë°”ë¡œ ì´ëŸ¬í•œ ì‘ì—…ë“¤ì„ ìˆ˜ì›”í•˜ê²Œ í•´ì£¼ëŠ” APIê°€ ë°”ë¡œ Pycocotoolsì…ë‹ˆë‹¤. Pycocotoolsì˜ ì—¬ëŸ¬ class ì¤‘ì—ì„œë„ ì˜¤ëŠ˜ ì†Œê°œí•˜ê³ ì í•˜ëŠ” classëŠ” COCO classì…ë‹ˆë‹¤. ì €ì½”ë“œê°€ ì–´ë µì§€ ì•Šì•„ì„œ ì½”ë“œ ì½ëŠ”ë° ì–´ë ¤ì›€ì´ ì—†ìœ¼ì‹œëŠ” ë¶„ë“¤ì€ [ê³µì‹ github](https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py))ì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCCKpFrfVdAt"
      },
      "source": [
        "%matplotlib inline\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "dataset_path = '/content/TACO/data'\n",
        "anns_file_path = dataset_path + '/' + 'annotations.json'\n",
        "\n",
        "# Read annotations\n",
        "with open(anns_file_path, 'r') as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "categories = dataset['categories']\n",
        "anns = dataset['annotations']\n",
        "imgs = dataset['images']\n",
        "nr_cats = len(categories)\n",
        "nr_annotations = len(anns)\n",
        "nr_images = len(imgs)\n",
        "\n",
        "# Load categories and super categories\n",
        "cat_names = []\n",
        "super_cat_names = []\n",
        "super_cat_ids = {}\n",
        "super_cat_last_name = ''\n",
        "nr_super_cats = 0\n",
        "for cat_it in categories:\n",
        "    cat_names.append(cat_it['name'])\n",
        "    super_cat_name = cat_it['supercategory']\n",
        "    # Adding new supercat\n",
        "    if super_cat_name != super_cat_last_name:\n",
        "        super_cat_names.append(super_cat_name)\n",
        "        super_cat_ids[super_cat_name] = nr_super_cats\n",
        "        super_cat_last_name = super_cat_name\n",
        "        nr_super_cats += 1\n",
        "\n",
        "print('Number of super categories:', nr_super_cats)\n",
        "print('Number of categories:', nr_cats)\n",
        "print('Number of annotations:', nr_annotations)\n",
        "print('Number of images:', nr_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlh8i2QqEOeH"
      },
      "source": [
        "## 1. Dataset statistics\n",
        "\n",
        "\n",
        "This shows the number of annotations per category:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTqVfGCl8cXw"
      },
      "source": [
        "# Count annotations\n",
        "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
        "for ann in anns:\n",
        "    cat_histogram[ann['category_id']] += 1\n",
        "\n",
        "# Initialize the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(5,15))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
        "df = df.sort_values('Number of annotations', 0, False)\n",
        "\n",
        "# Plot the histogram\n",
        "# sns.set_color_codes(\"pastel\")\n",
        "# sns.set(style=\"whitegrid\")\n",
        "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df,\n",
        "            label=\"Total\", color=\"b\")\n",
        "\n",
        "# fig = plot_1.get_figure()\n",
        "# fig.savefig(\"output.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NS9f1tSEcON"
      },
      "source": [
        "and this shows the number of annotations per super category:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwalZPiESFW"
      },
      "source": [
        "cat_ids_2_supercat_ids = {}\n",
        "for cat in categories:\n",
        "    cat_ids_2_supercat_ids[cat['id']] = super_cat_ids[cat['supercategory']]\n",
        "\n",
        "# Count annotations\n",
        "super_cat_histogram = np.zeros(nr_super_cats,dtype=int)\n",
        "for ann in anns:\n",
        "    cat_id = ann['category_id']\n",
        "    super_cat_histogram[cat_ids_2_supercat_ids[cat_id]] +=1\n",
        "    \n",
        "# Initialize the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(5,10))\n",
        "\n",
        "# Convert to DataFrame\n",
        "d ={'Super categories': super_cat_names, 'Number of annotations': super_cat_histogram}\n",
        "df = pd.DataFrame(d)\n",
        "df = df.sort_values('Number of annotations', 0, False)\n",
        "\n",
        "# sns.set_color_codes(\"pastel\")\n",
        "# sns.set(style=\"whitegrid\")\n",
        "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Super categories\", data=df,\n",
        "            label=\"Total\", color=\"b\")\n",
        "#plot_1.set_title('Annotations per super category',fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZTiiszGEvPW"
      },
      "source": [
        "### 1.1 Background stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R89chWuzEf11"
      },
      "source": [
        "# Get scene cat names\n",
        "scene_cats = dataset['scene_categories']\n",
        "scene_name = []\n",
        "for scene_cat in scene_cats:\n",
        "    scene_name.append(scene_cat['name'])\n",
        "\n",
        "nr_scenes = len(scene_cats)\n",
        "scene_cat_histogram = np.zeros(nr_scenes,dtype=int)\n",
        "\n",
        "for scene_ann in dataset['scene_annotations']:    \n",
        "    scene_ann_ids = scene_ann['background_ids']\n",
        "    for scene_ann_id in scene_ann_ids:\n",
        "        if scene_ann_id<len(scene_cats):\n",
        "            scene_cat_histogram[scene_ann_id]+=1\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'scene_cats': scene_cats, 'nr_annotations': scene_cat_histogram})\n",
        " \n",
        "# Plot\n",
        "colors = ['white','black','gray', 'gold', 'red','green','lightskyblue']\n",
        "plt.pie(scene_cat_histogram, labels=scene_name, colors = colors,\n",
        "      shadow=False, startangle=-120)\n",
        " \n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SRKZFfXFc0M"
      },
      "source": [
        "### 2. Visualize dataset graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs_Y75oHEzEo"
      },
      "source": [
        "from graphviz import Digraph\n",
        "# Note: graphviz may require more than pip installation due to path issue: e.g. brew install graphviz for mac\n",
        "\n",
        "#g = Digraph('G', filename='hello.gv')\n",
        "dot = Digraph('Dataset graph', filename='asd.gv')\n",
        "dot.attr(rankdir='LR', size='8,10')\n",
        "\n",
        "for cat_it in categories:\n",
        "    dot.node(cat_it['name'])\n",
        "    if cat_it['name']==cat_it['supercategory']:\n",
        "        dot.node(cat_it['supercategory'])\n",
        "    else:\n",
        "        dot.edge(cat_it['supercategory'], cat_it['name'])\n",
        "dot\n",
        "# Uncomment next line to print pdf\n",
        "#dot.view()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyjNMPzAFjLC"
      },
      "source": [
        "## 3. Visualize Annotated Images\n",
        "For simplicity, to select and show the dataset images with the respective masks, we make use of the COCO API. The script below shows how to load and visualize an image with all its annotations.\n",
        "\n",
        "Unfortunately, several python libraries do not take into account the EXIF orientation tag, thus we have to explicitly rotate the images. Alternatively you can use instead OpenCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlzWqjCIFgat"
      },
      "source": [
        "\n",
        "from PIL import Image, ExifTags\n",
        "from pycocotools.coco import COCO\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "import colorsys\n",
        "import random\n",
        "import pylab\n",
        "\n",
        "# User settings\n",
        "image_filepath = 'batch_11/000028.jpg'\n",
        "pylab.rcParams['figure.figsize'] = (28,28)\n",
        "####################\n",
        "\n",
        "# Obtain Exif orientation tag code\n",
        "for orientation in ExifTags.TAGS.keys():\n",
        "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "        break\n",
        "\n",
        "# Loads dataset as a coco object\n",
        "coco = COCO(anns_file_path)\n",
        "\n",
        "# Find image id\n",
        "img_id = -1\n",
        "for img in imgs:\n",
        "    if img['file_name'] == image_filepath:\n",
        "        img_id = img['id']\n",
        "        break\n",
        "\n",
        "# Show image and corresponding annotations\n",
        "if img_id == -1:\n",
        "    print('Incorrect file name')\n",
        "else:\n",
        "\n",
        "    # Load image\n",
        "    print(image_filepath)\n",
        "    I = Image.open(dataset_path + '/' + image_filepath)\n",
        "\n",
        "    # Load and process image metadata\n",
        "    if I._getexif():\n",
        "        exif = dict(I._getexif().items())\n",
        "        # Rotate portrait and upside down images if necessary\n",
        "        if orientation in exif:\n",
        "            if exif[orientation] == 3:\n",
        "                I = I.rotate(180,expand=True)\n",
        "            if exif[orientation] == 6:\n",
        "                I = I.rotate(270,expand=True)\n",
        "            if exif[orientation] == 8:\n",
        "                I = I.rotate(90,expand=True)\n",
        "\n",
        "    # Show image\n",
        "    fig,ax = plt.subplots(1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(I)\n",
        "\n",
        "    # Load mask ids\n",
        "    annIds = coco.getAnnIds(imgIds=img_id, catIds=[], iscrowd=None)\n",
        "    anns_sel = coco.loadAnns(annIds)\n",
        "\n",
        "    # Show annotations\n",
        "    for ann in anns_sel:\n",
        "        color = colorsys.hsv_to_rgb(np.random.random(),1,1)\n",
        "        for seg in ann['segmentation']:\n",
        "            poly = Polygon(np.array(seg).reshape((int(len(seg)/2), 2)))\n",
        "            p = PatchCollection([poly], facecolor=color, edgecolors=color,linewidths=0, alpha=0.4)\n",
        "            ax.add_collection(p)\n",
        "            p = PatchCollection([poly], facecolor='none', edgecolors=color, linewidths=2)\n",
        "            ax.add_collection(p)\n",
        "        [x, y, w, h] = ann['bbox']\n",
        "        rect = Rectangle((x,y),w,h,linewidth=2,edgecolor=color,\n",
        "                         facecolor='none', alpha=0.7, linestyle = '--')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTTlf31IF_X3"
      },
      "source": [
        "\n",
        "The script below shows how to filter images by either category or supercategory.\n",
        "\n",
        "Go ahead and try different (super)categories searches by changing the category_name. Note that small objects may be hard to see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EajaQlyLF6J2"
      },
      "source": [
        "from PIL import Image, ExifTags\n",
        "from pycocotools.coco import COCO\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "import colorsys\n",
        "import random\n",
        "import pylab\n",
        "\n",
        "# User settings\n",
        "nr_img_2_display = 10\n",
        "category_name = 'Bottle'#  --- Insert the name of one of the categories or super-categories above\n",
        "pylab.rcParams['figure.figsize'] = (14,14)\n",
        "####################\n",
        "\n",
        "# Obtain Exif orientation tag code\n",
        "for orientation in ExifTags.TAGS.keys():\n",
        "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "        break\n",
        "\n",
        "# Loads dataset as a coco object\n",
        "coco = COCO(anns_file_path)\n",
        "\n",
        "# Get image ids\n",
        "imgIds = []\n",
        "catIds = coco.getCatIds(catNms=[category_name])\n",
        "if catIds:\n",
        "    # Get all images containing an instance of the chosen category\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "else:\n",
        "    # Get all images containing an instance of the chosen super category\n",
        "    catIds = coco.getCatIds(supNms=[category_name])\n",
        "    for catId in catIds:\n",
        "        imgIds += (coco.getImgIds(catIds=catId))\n",
        "    imgIds = list(set(imgIds))\n",
        "\n",
        "nr_images_found = len(imgIds) \n",
        "print('Number of images found: ',nr_images_found)\n",
        "\n",
        "# Select N random images\n",
        "random.shuffle(imgIds)\n",
        "imgs = coco.loadImgs(imgIds[0:min(nr_img_2_display,nr_images_found)])\n",
        "\n",
        "for img in imgs:\n",
        "    image_path = dataset_path + '/' + img['file_name']\n",
        "    # Load image\n",
        "    I = Image.open(image_path)\n",
        "    \n",
        "    # Load and process image metadata\n",
        "    if I._getexif():\n",
        "        exif = dict(I._getexif().items())\n",
        "        # Rotate portrait and upside down images if necessary\n",
        "        if orientation in exif:\n",
        "            if exif[orientation] == 3:\n",
        "                I = I.rotate(180,expand=True)\n",
        "            if exif[orientation] == 6:\n",
        "                I = I.rotate(270,expand=True)\n",
        "            if exif[orientation] == 8:\n",
        "                I = I.rotate(90,expand=True)\n",
        "    \n",
        "    # Show image\n",
        "    fig,ax = plt.subplots(1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(I)\n",
        "\n",
        "    # Load mask ids\n",
        "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
        "    anns_sel = coco.loadAnns(annIds)\n",
        "    \n",
        "    # Show annotations\n",
        "    for ann in anns_sel:\n",
        "        color = colorsys.hsv_to_rgb(np.random.random(),1,1)\n",
        "        for seg in ann['segmentation']:\n",
        "            poly = Polygon(np.array(seg).reshape((int(len(seg)/2), 2)))\n",
        "            p = PatchCollection([poly], facecolor=color, edgecolors=color,linewidths=0, alpha=0.4)\n",
        "            ax.add_collection(p)\n",
        "            p = PatchCollection([poly], facecolor='none', edgecolors=color, linewidths=2)\n",
        "            ax.add_collection(p)\n",
        "        [x, y, w, h] = ann['bbox']\n",
        "        rect = Rectangle((x,y),w,h,linewidth=2,edgecolor=color,\n",
        "                         facecolor='none', alpha=0.7, linestyle = '--')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvk2HsjrKXi4"
      },
      "source": [
        "## annotations_unofficial_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftZ8LeRmGBpB"
      },
      "source": [
        "!python /content/TACO/download.py --dataset_path  /content/TACO/data/annotations_unofficial.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62bXgjiQKe7a"
      },
      "source": [
        "#Trash Detection with mask RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3C25W3HU_L"
      },
      "source": [
        "!python /content/TACO/detector/split_dataset.py --dataset_dir  /content/TACO/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LjuKwfqapeo"
      },
      "source": [
        "!python /content/TACO/detector/dataset.py --dataset_dir  /content/TACO/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpPmszVEbhlB"
      },
      "source": [
        "## EDA\n",
        "\n",
        "\n",
        "TACO and detect-waste\n",
        "\n",
        "This notebook contains several independent scripts that show how to load and visualize the dataset stats and annotated images:\n",
        "\n",
        "Section 1 : shows the dataset stats\n",
        "\n",
        "Section 2 : shows the class hierarchical structure: super classes and classes\n",
        "\n",
        "Section 3 : shows TACO images along with their segmentation masks\n",
        "But first we need to load the annotations and some python libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsPfW9ZEax-Z"
      },
      "source": [
        "%matplotlib inline\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "\n",
        "from PIL import Image, ExifTags\n",
        "from pycocotools.coco import COCO\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "import colorsys\n",
        "import random\n",
        "import pylab\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "module_path = str(Path.cwd().parents[0] / \"src\")\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "\n",
        "dataset_path = '/content/TACO/data'\n",
        "anns_file_path = dataset_path + '/' + 'annotations.json'\n",
        "epinote_dataset_path = '/dih4/dih4_2/wimlds/data/not-annotated'\n",
        "epinote_anns_file_path = '/dih4/dih4_2/wimlds/data/annotations_epi.json'\n",
        "# Read annotations\n",
        "with open(anns_file_path, 'r') as f:\n",
        "    dataset = json.loads(f.read())\n",
        "with open(epinote_anns_file_path, 'r') as f:\n",
        "    epinote_dataset = json.loads(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfxxktlgau16"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}